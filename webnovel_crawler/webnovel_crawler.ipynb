{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import codecs\n",
    "import pickle\n",
    "from pandas import Series, DataFrame\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오늘의 웹소설\n",
    "---\n",
    "http://novel.naver.com/webnovel/weekdayList.nhn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = 'http://novel.naver.com'\n",
    "genre_base_url = 'http://novel.naver.com/webnovel/genre.nhn?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#로맨스, 로맨스판타지, 판타지, 무협,미스터리,역사/전쟁, 라이트노벨, 퓨전\n",
    "# 장르 이름 : [url_num, 'url_sep']\n",
    "genre_item_list = {\n",
    "    'romance' : [101, 'rom'], \n",
    "    'romancefantasy' : [109, 'rof'], \n",
    "    'fantasy' : [102, 'sff'], \n",
    "    'action' :[103, 'hro'],\n",
    "    'mystery' : [104,'mth'],\n",
    "    'history&war' :[105, 'his'], \n",
    "    'lightnovel' :[106, 'lno'], \n",
    "    'fusion' : [108, 'fus']\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 장르별 소설 url dict 가져옴\n",
    "def get_novel_url_dict(genre_name, finished):\n",
    "    novel_dict = {} # 소설 제목 : 소설 url 형태로 return\n",
    "    \n",
    "    genre_item = genre_item_list[genre_name]\n",
    "    genre_num = genre_item[0]\n",
    "    url_sep = genre_item[1]\n",
    "    \n",
    "    for page_num in range(1,20):\n",
    "        params = {\n",
    "            'genre' : genre_num,\n",
    "            'page' : page_num,\n",
    "        }\n",
    "\n",
    "        if finished: # 완결작일경우 url 다름\n",
    "            params['order'] = 'Read'\n",
    "            params['finish']= 'true'\n",
    "\n",
    "        r = requests.get('http://novel.naver.com/webnovel/genre.nhn?', params=params)\n",
    "        crawler = BeautifulSoup(r.content, 'html.parser')\n",
    "        \n",
    "        class_temp = 'list_type1 v2 NE=a:lst_' + url_sep\n",
    "        novel_list = crawler.find('ul', {'class' :class_temp}).findAll('li')\n",
    "        for novel in novel_list:\n",
    "            url = novel.a.attrs['href'] # url\n",
    "            title = novel.find('p', {'class': 'subj v3'}).contents[0] # title\n",
    "            if title in novel_dict:\n",
    "                print(str(page_num) + '페이지에서 완료')\n",
    "                return novel_dict\n",
    "            else:\n",
    "                novel_dict[title] = base_url + url\n",
    "        time.sleep(0.05)\n",
    "    return novel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#유효한 response인지 검사\n",
    "def valid_status(response):\n",
    "    if response.status_code == 200:\n",
    "        return True\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TITLE_TOKEN = '<title>'\n",
    "TALK_TOKEN = '<talk>'\n",
    "QUOTES = '[“”‘’-]' # will be stripped\n",
    "\n",
    "# url로부터 내용 읽어서 파싱\n",
    "def get_content_from_url(content_page_url):\n",
    "    content = ''\n",
    "    r = requests.get(content_page_url)\n",
    "    if valid_status(r):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"오류 발생 : {}\".format(content_page_url))\n",
    "        return ''\n",
    "    \n",
    "    crawler = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    title = crawler.find('h2', {'class': 'detail_view_header'}).contents[0] # 몇화 제목\n",
    "    content += TITLE_TOKEN + title + '\\r\\n\\r\\n'\n",
    "    \n",
    "    line_list = crawler.find('div', {'class': 'detail_view_content ft15'}).find_all('p')\n",
    "    for line in line_list :\n",
    "        if line.has_attr('class') == False: # general sentence\n",
    "            processed_sentence = line.get_text().strip()\n",
    "            content += processed_sentence\n",
    "        elif 'talk' in line['class']: # talk\n",
    "            processed_talk = line.get_text().strip().strip(QUOTES).strip()\n",
    "            content += TALK_TOKEN + processed_talk\n",
    "        elif 'pic' in line['class']: # picture\n",
    "            pass\n",
    "        else:\n",
    "            print('기타 태그 오류 발생')\n",
    "            print('line')\n",
    "        content = content + '\\r\\n'\n",
    "    time.sleep(0.05)\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# url_list로부터 읽어와서 텍스트 파일에 저장\n",
    "def crawl_and_write(genre, novel_url_dict, finished):\n",
    "    if finished:\n",
    "        finish_string = '완결'\n",
    "    else:\n",
    "        finish_string = '미완결'\n",
    "    print('{} {} 장르 총 url {}개'.format(finish_string, genre, len(novel_url_dict)))\n",
    "    print('----------------------------------------')\n",
    "    check_index = 0\n",
    "\n",
    "    for title, url in novel_url_dict.items():\n",
    "        check_index = check_index + 1\n",
    "        file_name = title + '.txt' # filename\n",
    "        file_name = re.sub('[\\/:*?\"<>|]','',file_name) # file명 형식에 맞게 수정\n",
    "\n",
    "        r = requests.get(url)\n",
    "        crawler = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "        total = int(crawler.find(\"span\", {\"class\" : \"total\"}).get_text()[1:-1]) #전체 회차\n",
    "        if total == 0: # 회차 없으면 멈춤\n",
    "            break;\n",
    "        page_limit = total // 10 #한 페이지에 10개씩\n",
    "        if total % 10 != 0:\n",
    "            page_limit += 1\n",
    "#         print(total)\n",
    "#         print(page_limit)\n",
    "        \n",
    "        # 완결/미완결에 따라 분기\n",
    "        if finished:\n",
    "            iterate_range = range(1, page_limit+1)\n",
    "        else:\n",
    "            iterate_range = range(1, page_limit+1)\n",
    "        \n",
    "        novel_content_list = []\n",
    "        for page_num in iterate_range:\n",
    "            r = requests.get(url, params = {'page': page_num})\n",
    "    #         print(r.url)\n",
    "            crawler = BeautifulSoup(r.content, \"html.parser\")\n",
    "            page_novel_content_list = crawler.find(\"ul\", {\"class\": \"list_type2 v3 NE=a:lst\"}).findAll(\"li\") # 이 페이지의 모든 소설 리스트\n",
    "            novel_content_list.extend(page_novel_content_list)\n",
    "            \n",
    "        if not finished:\n",
    "            novel_content_list.reverse()\n",
    "            \n",
    "        write_string = ''\n",
    "        for novel_content in novel_content_list:\n",
    "            content_url = novel_content.a.attrs['href']\n",
    "            content_page_url = base_url + content_url #소설 내용 url\n",
    "            write_string  = write_string + get_content_from_url(content_page_url)\n",
    "\n",
    "        with codecs.open(os.path.join(directory, file_name), 'w', encoding = 'utf-8') as f: #file에 write\n",
    "            f.write(write_string)\n",
    "        print('{} : 저장 성공'.format(title))\n",
    "        \n",
    "    # 진행 상황 출력\n",
    "    if check_index % 10 == 0:\n",
    "        print(\"** 현재 \" + str(check_index) +\"개 진행중...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2페이지에서 완료\n",
      "미완결 history&war 장르 총 url 1개\n",
      "----------------------------------------\n",
      "연못에 핀 목화 - 송경별곡 : 저장 성공\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2페이지에서 완료\n",
      "완결 lightnovel 장르 총 url 10개\n",
      "----------------------------------------\n",
      "이사님의 취미생활 : 저장 성공\n",
      "마성의 가정부 : 저장 성공\n",
      "이 집사님의 사랑법 : 저장 성공\n",
      "협박연애 : 저장 성공\n",
      "형의 그녀 : 저장 성공\n",
      "납치 감금에서 시작되는 우리들의 사바트 : 저장 성공\n",
      "애유기 : 저장 성공\n",
      "사또의 여자가 되겠나이다 : 저장 성공\n",
      "여왕의 아이돌 : 저장 성공\n",
      "앨리스 드라이브 : 저장 성공\n",
      "** 현재 10개 진행중...\n",
      "\n",
      "\n",
      "2페이지에서 완료\n",
      "미완결 lightnovel 장르 총 url 3개\n",
      "----------------------------------------\n",
      "용왕님의 셰프가 되었습니다 : 저장 성공\n",
      "전설의 공돌이 : 저장 성공\n",
      "편의점에서 그녀와 창세하고 있습니다 : 저장 성공\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2페이지에서 완료\n",
      "완결 fusion 장르 총 url 11개\n",
      "----------------------------------------\n",
      "백의서소 : 저장 성공\n",
      "우아한 환생 : 저장 성공\n",
      "광야의 야수들 : 저장 성공\n",
      "드라마입니까 : 저장 성공\n",
      "레이븐: 여왕의 수호 목걸이 : 저장 성공\n",
      "고스트 게이트 : 저장 성공\n",
      "채널 나인 : 저장 성공\n",
      "개경 세원록 : 저장 성공\n",
      "빈틈없이 고요하게 : 저장 성공\n",
      "언어영역 완전정복 : 저장 성공\n",
      "** 현재 10개 진행중...\n",
      "계와 과학자 : 저장 성공\n",
      "\n",
      "\n",
      "2페이지에서 완료\n",
      "미완결 fusion 장르 총 url 1개\n",
      "----------------------------------------\n",
      "조선공주실록 : 저장 성공\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = r'C:\\Users\\kwj96\\Desktop\\YBigta\\웹소설 공모전\\webnovel_data'\n",
    "for genre in genre_item_list.keys():\n",
    "    directory = os.path.join(base_dir, genre)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    for finished in True,False: #완결, 미완결\n",
    "        if (genre == 'history&war') & (finished == True):\n",
    "            continue\n",
    "        novel_url_dict = get_novel_url_dict(genre, finished) #장르별 소설 url list\n",
    "        crawl_and_write(genre, novel_url_dict, finished) #파일에 저장\n",
    "        print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오늘의 웹소설 Metadata\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = 'http://novel.naver.com'\n",
    "genre_base_url = 'http://novel.naver.com/webnovel/genre.nhn?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#로맨스, 로맨스판타지, 판타지, 무협,미스터리,역사/전쟁, 라이트노벨, 퓨전\n",
    "# 장르 이름 : [url_num, 'url_sep']\n",
    "genre_item_list = {\n",
    "    'romance' : [101, 'rom'], \n",
    "    'romancefantasy' : [109, 'rof'], \n",
    "    'fantasy' : [102, 'sff'], \n",
    "    'action' :[103, 'hro'],\n",
    "    'mystery' : [104,'mth'],\n",
    "    'history&war' :[105, 'his'], \n",
    "    'lightnovel' :[106, 'lno'], \n",
    "    'fusion' : [108, 'fus']\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metadata\n",
    "# {'10도, 우리 연애의 온도차': ['설래인', 483047, 8, 9.97, 24066]}\n",
    "# {제목 : [작가,novelid, 총 회차, 평점, 관심수]}\n",
    "def get_metadata_dict(genre_name, finished):\n",
    "    metadata_dict = {}\n",
    "    \n",
    "    genre_item = genre_item_list[genre_name]\n",
    "    genre_num = genre_item[0]\n",
    "    url_sep = genre_item[1]\n",
    "    \n",
    "    for page_num in range(1,20):\n",
    "        params = {\n",
    "            'genre' : genre_num,\n",
    "            'page' : page_num,\n",
    "        }\n",
    "\n",
    "        if finished: # 완결작일경우 url 다름\n",
    "            params['order'] = 'Read'\n",
    "            params['finish']= 'true'\n",
    "\n",
    "        r = requests.get('http://novel.naver.com/webnovel/genre.nhn?', params=params)\n",
    "        crawler = BeautifulSoup(r.content, 'html.parser')\n",
    "        \n",
    "        class_temp = 'list_type1 v2 NE=a:lst_' + url_sep\n",
    "        novel_list = crawler.find('ul', {'class' :class_temp}).findAll('li')\n",
    "        for novel in novel_list:\n",
    "            url = novel.a.attrs['href'] # url\n",
    "            novel_id = url.split('=')[-1] #novel_id\n",
    "            title = novel.find('p', {'class': 'subj v3'}).contents[0] # title\n",
    "            title = re.sub('[\\/:*?\"<>|]','',title) #특수문자 제거\n",
    "            author = novel.find('span',{'class':'ellipsis'}).get_text() # author\n",
    "            total_episode = novel.find('span',{'class':'num_total'}).get_text()[2:-1] # total_episode\n",
    "            star_rating = novel.find('span',{'class':'score_area'}).get_text()[2:] #별점\n",
    "            attention_rating = novel.find('span',{'class':'info_text'}).get_text()[2:].replace(',', '') #관심 개수\n",
    "            if attention_rating[-1] == '만':\n",
    "                attention_rating = float(attention_rating[:-1]) * 10000\n",
    "            \n",
    "            if title in metadata_dict:\n",
    "                print(str(page_num) + '페이지에서 완료')\n",
    "                return metadata_dict\n",
    "            else:\n",
    "                metadata_dict[title] = [author, int(novel_id), int(total_episode), float(star_rating), int(attention_rating)]\n",
    "        time.sleep(0.05)\n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10페이지에서 완료\n",
      "4페이지에서 완료\n",
      "** romance 장르 완료\n",
      "3페이지에서 완료\n",
      "2페이지에서 완료\n",
      "** romancefantasy 장르 완료\n",
      "3페이지에서 완료\n",
      "2페이지에서 완료\n",
      "** fantasy 장르 완료\n",
      "3페이지에서 완료\n",
      "2페이지에서 완료\n",
      "** action 장르 완료\n",
      "3페이지에서 완료\n",
      "2페이지에서 완료\n",
      "** mystery 장르 완료\n",
      "2페이지에서 완료\n",
      "** history&war 장르 완료\n",
      "2페이지에서 완료\n",
      "2페이지에서 완료\n",
      "** lightnovel 장르 완료\n",
      "2페이지에서 완료\n",
      "2페이지에서 완료\n",
      "** fusion 장르 완료\n"
     ]
    }
   ],
   "source": [
    "metadata_dict = {}\n",
    "for genre in genre_item_list.keys():\n",
    "    for finished in True,False: #완결, 미완결\n",
    "        if (genre == 'history&war') & (finished == True):\n",
    "            continue\n",
    "        metadata_dict.update(get_metadata_dict(genre, finished))\n",
    "    print('** %s 장르 완료' % genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save metadata as pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('metadata_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(metadata_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load pickle file\n",
    "# with open('metadata_dict.pickle', 'rb') as handle:\n",
    "#     dic = pickle.load(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alpacapaca/infinityWord\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.seq2seq_datasets import Seq2SeqIndexedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.encoders.rnn_encoder import GRUEncoder\n",
    "from models.decoders.rnn_decoder import GRUDecoder\n",
    "from models.rnn_model import RNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers.seq2seq_trainer import Seq2SeqTrainer, seq2seq_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.base_datasets import SentencesTokenizedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionaries import BaseDictionary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sentences_dataset = SentencesTokenizedDataset(phase='train')\n",
    "\n",
    "dictionary = BaseDictionary()\n",
    "dictionary.prepare_dictionary(sentences_dataset)\n",
    "dictionary.save('base_dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48034"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = BaseDictionary.load('base_dictionary')\n",
    "dictionary.vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = nn.Embedding(num_embeddings=dictionary.vocabulary_size, embedding_dim=128)\n",
    "encoder = GRUEncoder(embeddings, hidden_size=256)\n",
    "decoder = GRUDecoder(embeddings, hidden_size=256)\n",
    "model = RNNModel(encoder, decoder)\n",
    "logger = get_logger(log_name='gru_encoder_decoder')\n",
    "trainer = Seq2SeqTrainer(model=model, \n",
    "                         train_dataloader=DataLoader(Seq2SeqIndexedDataset('train'), batch_size=32, collate_fn=seq2seq_collate_fn), \n",
    "                         val_dataloader=DataLoader(Seq2SeqIndexedDataset('val'), batch_size=32, collate_fn=seq2seq_collate_fn),\n",
    "                         loss_function=CrossEntropyLoss(size_average=False),\n",
    "                         optimizer=Adam(model.parameters()),\n",
    "                         device=device,\n",
    "                         logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/817 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 07-30 18:58:21 > Epoch: 0   Progress: 0.0% (0:01:32.889739) Train Loss: 10.6721 Val Loss: 5.37086 Train Perplexity: 4.31e+04 Val Perplexity: 2.15e+02 Learning rate: 0.001 \n",
      "[INFO] 07-30 18:58:21 > Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 817/817 [02:18<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 07-30 19:02:11 > Epoch: 1   Progress: 10.0% (0:05:22.630113) Train Loss: 3.97414 Val Loss: 4.02294 Train Perplexity: 53.2 Val Perplexity: 55.9 Learning rate: 0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 817/817 [02:18<00:00,  5.90it/s]\n",
      " 50%|████▉     | 406/817 [00:52<00:53,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 07-30 19:09:53 > Epoch: 3   Progress: 30.0% (0:13:04.086236) Train Loss: 3.44487 Val Loss: 4.03098 Train Perplexity: 31.3 Val Perplexity: 56.3 Learning rate: 0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 817/817 [02:14<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 07-30 19:13:38 > Epoch: 4   Progress: 40.0% (0:16:49.651528) Train Loss: 3.29506 Val Loss: 4.14242 Train Perplexity: 27.0 Val Perplexity: 63.0 Learning rate: 0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 817/817 [02:17<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 07-30 19:17:27 > Epoch: 5   Progress: 50.0% (0:20:38.365453) Train Loss: 3.11329 Val Loss: 4.5619 Train Perplexity: 22.5 Val Perplexity: 95.8 Learning rate: 0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 817/817 [02:20<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 07-30 19:21:19 > Epoch: 6   Progress: 60.0% (0:24:30.169223) Train Loss: 2.905 Val Loss: 4.66593 Train Perplexity: 18.3 Val Perplexity: 1.06e+02 Learning rate: 0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 817/817 [02:09<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 07-30 19:25:00 > Epoch: 7   Progress: 70.0% (0:28:11.274724) Train Loss: 2.69608 Val Loss: 4.92483 Train Perplexity: 14.8 Val Perplexity: 1.38e+02 Learning rate: 0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 83/817 [00:05<00:52, 13.98it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.run(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionaries import BaseDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = BaseDictionary.load('base_dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([dictionary['<StartSent>']]).unsqueeze(0)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(50000, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 1024, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (decoder): Linear(in_features=1024, out_features=50000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'탄탄대로의'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.idx2word[softmax(model(inputs), dim=2).argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generators import OneSentenceGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = OneSentenceGenerator(model, dictionary, checkpoint_filepath='parameters/LSTM/LSTM_0_2018-07-28 19:31:26.237748.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'머리에는 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.generate_one()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda]",
   "language": "python",
   "name": "conda-env-conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
